{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generalized_factorization_machine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/j1LcE0v332U3LqhuXMPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoetGer/decisions-under-uncertainty/blob/main/generalized_factorization_machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2i8NyhXJKh1",
        "outputId": "00553d98-e6eb-4265-f535-399b5f3b9b66"
      },
      "source": [
        "! pip install tf2_fm_zoo"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf2_fm_zoo\n",
            "  Downloading https://files.pythonhosted.org/packages/03/29/d9bfaf9ceb3d83cf130d53225621bd9def15a4cfdb5e23a51ee3593e255a/tf2_fm_zoo-0.1.0-py3-none-any.whl\n",
            "Installing collected packages: tf2-fm-zoo\n",
            "Successfully installed tf2-fm-zoo-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7HMwW6vJilD",
        "outputId": "c6e06312-fd52-43aa-a57a-8c784f1bd016"
      },
      "source": [
        "! git clone https://github.com/RoetGer/tf2-dist-utils.git\n",
        "! pip install tf2-dist-utils/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tf2-dist-utils'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 108 (delta 54), reused 84 (delta 33), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (108/108), 14.34 KiB | 4.78 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Processing ./tf2-dist-utils\n",
            "Building wheels for collected packages: tf2-dist-utils\n",
            "  Building wheel for tf2-dist-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf2-dist-utils: filename=tf2_dist_utils-0.0.1-cp37-none-any.whl size=5013 sha256=1067064fb1344708e2a47e588a0eaa19a0f6b1799e12f6f81de3442fc560374c\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/19/9a/458755d03517c7db63abf5bc1289da1648304c3cf9ef3789ba\n",
            "Successfully built tf2-dist-utils\n",
            "Installing collected packages: tf2-dist-utils\n",
            "Successfully installed tf2-dist-utils-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SORgTZKtMt79",
        "outputId": "5e022433-e3d4-40ec-e7a8-2c585f789211"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "from fm_zoo.fm import FactorizationMachine\n",
        "\n",
        "\n",
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X = X[:,:3]\n",
        "y = tf.cast(y, dtype=tf.float32)\n",
        "\n",
        "kbd = KBinsDiscretizer(n_bins=15, encode=\"ordinal\")\n",
        "\n",
        "nunique_vals = pd.DataFrame(X).nunique()\n",
        "X = tf.cast(kbd.fit_transform(X), dtype=tf.int64)\n",
        "\n",
        "fm = FactorizationMachine(\n",
        "    feature_cards=tf.cast(nunique_vals, tf.int32), \n",
        "    factor_dim=3)\n",
        "\n",
        "fm.compile(loss=tf.keras.losses.mean_squared_error, optimizer=\"Adam\")\n",
        "hist = fm.fit(\n",
        "    X, y, \n",
        "    validation_split=0.15, \n",
        "    batch_size=16,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "      tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "    ])\n",
        "\n",
        "pd.DataFrame(hist.history).plot(figsize=(15,10))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
            "  'decreasing the number of bins.' % jj)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
            "  'decreasing the number of bins.' % jj)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "27/27 [==============================] - 1s 7ms/step - loss: 606.1400 - val_loss: 302.7391\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 675.3328 - val_loss: 299.8024\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 587.3767 - val_loss: 296.2664\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 648.5741 - val_loss: 291.9159\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 598.5106 - val_loss: 286.9246\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 670.7343 - val_loss: 281.1377\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 630.2023 - val_loss: 274.9049\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 582.7244 - val_loss: 267.6220\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 616.3528 - val_loss: 260.1917\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 564.5907 - val_loss: 252.1932\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 560.8579 - val_loss: 243.7300\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 570.8912 - val_loss: 234.8336\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 542.7464 - val_loss: 225.9159\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 523.6835 - val_loss: 216.6279\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 490.4304 - val_loss: 206.9202\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 512.1128 - val_loss: 197.1830\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 537.9457 - val_loss: 187.5317\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 439.4944 - val_loss: 177.7732\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 467.4917 - val_loss: 168.0038\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 426.6738 - val_loss: 158.3031\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 415.9150 - val_loss: 148.7811\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 358.8434 - val_loss: 139.8121\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 378.8356 - val_loss: 130.3341\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 375.1988 - val_loss: 121.4510\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 356.6375 - val_loss: 113.3341\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 365.2956 - val_loss: 105.0256\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 322.8314 - val_loss: 96.9196\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 321.7386 - val_loss: 89.8063\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 285.9031 - val_loss: 82.9270\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 262.4613 - val_loss: 75.7740\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 241.0898 - val_loss: 69.6994\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 260.8934 - val_loss: 63.8536\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 240.6126 - val_loss: 58.6144\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 205.5991 - val_loss: 53.9587\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 194.9394 - val_loss: 49.2452\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 231.1033 - val_loss: 44.9926\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 207.2379 - val_loss: 41.2220\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 197.7509 - val_loss: 38.0026\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 156.3154 - val_loss: 34.9040\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 171.2045 - val_loss: 32.3734\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 146.4544 - val_loss: 30.0083\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 178.6920 - val_loss: 27.9253\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 125.4122 - val_loss: 26.3139\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 145.9335 - val_loss: 24.7286\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 138.5159 - val_loss: 23.5985\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 129.4071 - val_loss: 22.4480\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 130.7935 - val_loss: 21.5921\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 117.3805 - val_loss: 20.9087\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 97.7100 - val_loss: 20.3935\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 128.4181 - val_loss: 20.0001\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 97.6182 - val_loss: 19.7369\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 92.6566 - val_loss: 19.4880\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 89.4558 - val_loss: 19.3918\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 84.0261 - val_loss: 19.3012\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 88.5514 - val_loss: 19.3244\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 93.4665 - val_loss: 19.3403\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 87.6613 - val_loss: 19.4729\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 92.6152 - val_loss: 19.6108\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 82.2779 - val_loss: 19.7632\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 80.3783 - val_loss: 19.9141\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 73.1307 - val_loss: 20.0597\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 66.4707 - val_loss: 20.2165\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 63.8597 - val_loss: 20.4106\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 72.5802 - val_loss: 20.5818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3915ae9b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAmQL3JTl4zz"
      },
      "source": [
        "import tensorflow_probability as tfp\n",
        "import tf2_dist_utils as tfdu\n",
        "from tf2_dist_utils.distributions import TransObj\n",
        "#from tf2_dist_utils.losses import \n",
        "tfd = tfp.distributions"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RUTAVrrVThn"
      },
      "source": [
        "import inspect\n",
        "from functools import partial\n",
        "from tf2_dist_utils.distributions import TransNormal\n",
        "\n",
        "class NegLogLikeLoss(tf.keras.losses.Loss):\n",
        "    '''Base class for negative loglikelihood based losses'''\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        '''Computes log-probability of observations\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        y_true : tf.tensor\n",
        "            Observations\n",
        "        y_pred : tf.tensor\n",
        "            Parameter values of the distribution underlying the loss.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        tf.tensor\n",
        "            Negative loglikelihood for each observation.\n",
        "        '''\n",
        "\n",
        "        shape = y_pred.shape\n",
        "        '''\n",
        "                if len(y_pred.shape) > 1:\n",
        "                  lst = tf.split(\n",
        "                    y_pred, \n",
        "                    num_or_size_splits=shape[-1], \n",
        "                    axis=(shape.ndims - 1))\n",
        "                else:\n",
        "                  lst = [y_pred]\n",
        "        '''        \n",
        "        rv = self.dist(*y_pred)#*lst)\n",
        "\n",
        "        return -rv.log_prob(y_true)\n",
        "\n",
        "def build_loss(class_loss_name, dist, params=None, **kwargs):\n",
        "    '''Creates a tensorflow 2.x loss function based on NegLokLikeLoss\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    class_loss_name : str\n",
        "        Name/Type of the loss to be created, e.g. \"TransNormal\"\n",
        "    dist : distribution object\n",
        "        Can be any type of tensorflow distribution object, \n",
        "        which supports parameter specification via call \n",
        "        (e.g. dist(param1, param2)) and has a log_prob method\n",
        "    params : list[str]\n",
        "        Specifies which parameters should be exposed for optimization\n",
        "    **kwargs : dict\n",
        "        kwargs can be used to fix attributes of the distribution\n",
        "        object, e.g. if you want to create a loss function based on a\n",
        "        Gaussian distribution with location set to 0, you can simply\n",
        "        forward loc=0.0.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Object of type class_loss_name\n",
        "        Loss object of type class_loss_name which can be used\n",
        "        in conjuction with tensorflow 2.x models.\n",
        "    '''\n",
        "    \n",
        "    if kwargs:\n",
        "        dist = partial(dist, **kwargs)\n",
        "\n",
        "    if params:\n",
        "        dist = expose_params(dist, params)\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dist = dist\n",
        "        super(NegLogLikeLoss, self).__init__()\n",
        "\n",
        "    loss = type(\n",
        "        class_loss_name,\n",
        "        (NegLogLikeLoss,),\n",
        "        {\n",
        "            \"__init__\": __init__\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def expose_params(func, params):\n",
        "    func_header = \", \".join(params)\n",
        "    func_call = \", \".join([\n",
        "        p + \"=\" + p for p in params\n",
        "    ])\n",
        "\n",
        "    nparams = len(params)\n",
        "\n",
        "    func_str = f'''\n",
        "    class ExpParam:\n",
        "      def __init__(self, func):\n",
        "        self.func = func\n",
        "        self.nparams = {nparams}\n",
        "      \n",
        "      def __call__(self, {func_header}):\n",
        "          return self.func({func_call})\n",
        "      \n",
        "      def get_nparams(self):\n",
        "          return self.nparams\n",
        "    '''\n",
        "\n",
        "    exec(inspect.cleandoc(func_str))\n",
        "\n",
        "    return eval(\"ExpParam(func)\")\n",
        "\n",
        "NegGaussLogLikeLoss = build_loss(\"NegGaussLogLikeLoss\", TransNormal)\n",
        "\n",
        "fTransNormal = partial(TransNormal, loc=0.0)\n",
        "RestrTransNormal = expose_params(fTransNormal, [\"scale\"])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM_sl_-n8qIj"
      },
      "source": [
        "ttt = build_loss(\"GLossScaleOnly\", tfd.Normal, params=[\"scale\"], loc=0.0)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e77uxTvo9P88",
        "outputId": "e5515129-fb11-4331-ba1d-58b0e2011037"
      },
      "source": [
        "RestrTransNormal(1.)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hs8Qc0_2iTW",
        "outputId": "1cf561e2-d63e-4094-e932-5044ee85f06b"
      },
      "source": [
        "inspect.signature(ttt.__call__).parameters"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mappingproxy({'sample_weight': <Parameter \"sample_weight=None\">,\n",
              "              'self': <Parameter \"self\">,\n",
              "              'y_pred': <Parameter \"y_pred\">,\n",
              "              'y_true': <Parameter \"y_true\">})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGGKa19o2yvW",
        "outputId": "b456e0f4-3194-4c8a-99d7-11fd9c109d44"
      },
      "source": [
        "ttt()(y_true=[1.,2.], y_pred=tf.constant([1., 1.]))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.1689386>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G5FwNQe56mf",
        "outputId": "f1a7f8f1-95f1-4db0-a055-fe8b46c4c0bb"
      },
      "source": [
        "y_pred = tf.constant([[1., 1.], [2., 3.]])\n",
        "\n",
        "@tf.function()\n",
        "def tfunc(y_pred):\n",
        "  shape = y_pred.shape\n",
        "\n",
        "  if len(y_pred.shape) > 1:\n",
        "    lst = tf.split(\n",
        "      y_pred, \n",
        "      num_or_size_splits=shape[-1], \n",
        "      axis=(shape.ndims - 1))\n",
        "  else:\n",
        "    lst = [y_pred]\n",
        "\n",
        "  return lst\n",
        "\n",
        "tfunc(y_pred)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              " array([[1.],\n",
              "        [2.]], dtype=float32)>, <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              " array([[1.],\n",
              "        [3.]], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "nBWTcGud87xV",
        "outputId": "9431cfde-6361-4b09-fc20-66581379570d"
      },
      "source": [
        "ttt(tf.constant([1.,2.,4.]), tf.constant([2., 4.,6.]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5fbfd362deaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mttt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8vKqxVG7cU-",
        "outputId": "80eeee9a-fb3d-4860-df8a-714a0d07c308"
      },
      "source": [
        "TransNormal(loc=0.0, scale=2.0).sample(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([15.417641 ,  9.440426 ,  9.523952 , -2.8832717,  1.0117764,\n",
              "       -5.144701 ,  2.988882 , -9.784966 , -0.3747246, 10.014172 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWLGf3CG5xUf"
      },
      "source": [
        "import tensorflow.keras as tfk\n",
        "import tensorflow.keras.layers as tfkl\n",
        "\n",
        "class GenFactMachine():\n",
        "\n",
        "    def __init__(self, dist, feature_cards, factor_dim):\n",
        "        self.dist = dist\n",
        "        self.feature_cards = feature_cards\n",
        "        self.factor_dim = factor_dim\n",
        "        self.n_params = len(inspect.signature(dist).parameters)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.loss = build_loss(\"GFMloss\", self.dist)\n",
        "\n",
        "        self.model = self._build_model(X)\n",
        "\n",
        "        hist = self.model.fit(\n",
        "            X, y,\n",
        "            validation_split=0.15, \n",
        "            batch_size=16,\n",
        "            epochs=100,\n",
        "            callbacks=[\n",
        "              tfk.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "            ])\n",
        "        \n",
        "        return hist\n",
        "\n",
        "    def predict(self, X, y, nsamples=None):\n",
        "        params = self.model.predict(X)\n",
        "        \n",
        "        shape = params.shape\n",
        "\n",
        "        # model.predict returns tensor of parameters\n",
        "        # dist objects are assumed to take the individual\n",
        "        # columns of the tensor as input\n",
        "        if len(shape) > 1:\n",
        "          lst = tf.split(\n",
        "            params, \n",
        "            num_or_size_splits=shape[-1], \n",
        "            axis=(shape.ndims - 1))\n",
        "        else:\n",
        "          lst = [params]\n",
        "        \n",
        "        if nsamples:\n",
        "          preds = self.dist(*lst).sample(nsamples)\n",
        "        else:\n",
        "          preds = self.dist(*lst).mean()   \n",
        "\n",
        "        return preds\n",
        "\n",
        "    def _build_model(self, X):\n",
        "\n",
        "        inputs_ = tfk.Input(shape=X.shape[1])\n",
        "\n",
        "        self.fms = [\n",
        "            FactorizationMachine(\n",
        "              feature_cards=self.feature_cards, \n",
        "              factor_dim=self.factor_dim)\n",
        "            for _ in range(self.n_params)        \n",
        "        ]\n",
        "\n",
        "        params = [\n",
        "            fm(inputs_) for fm in self.fms          \n",
        "        ]\n",
        "        params = tfkl.Concatenate(params)\n",
        "\n",
        "        model = tfk.Model(inputs=inputs_, outputs=params)\n",
        "\n",
        "        model.compile(\n",
        "            loss=self.loss,\n",
        "            optimizer=keras.optimizers.RMSprop())\n",
        "        \n",
        "        return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDXdG0iH9bYZ"
      },
      "source": [
        "dist=TransNormal\n",
        "feature_cards=tf.cast(nunique_vals, tf.int32)\n",
        "factor_dim=3\n",
        "n_params = 2\n",
        "\n",
        "loss = build_loss(\"GFMloss\", dist)\n",
        "\n",
        "inputs_ = tfk.Input(shape=X.shape[1], dtype=X.dtype)\n",
        "\n",
        "fms = [\n",
        "    FactorizationMachine(\n",
        "      feature_cards=feature_cards, \n",
        "      factor_dim=factor_dim,\n",
        "      name=\"sub_mdl_\" + str(i))\n",
        "    for i in range(n_params)        \n",
        "]\n",
        "\n",
        "params = [\n",
        "    fm(inputs_) for fm in fms          \n",
        "]\n",
        "#params = tfkl.Concatenate(params)\n",
        "\n",
        "model = tfk.Model(inputs=inputs_, outputs=params)\n",
        "\n",
        "model.compile(\n",
        "    loss=loss,\n",
        "    optimizer=tfk.optimizers.RMSprop())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "GRLOobFV-dP5",
        "outputId": "73f648f4-8002-4e15-c88a-c4b2c4f6ddc9"
      },
      "source": [
        "model.fit(X, y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6d10fe8973eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n\n    TypeError: __init__() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "csJyd-Wz8HA_",
        "outputId": "07cd3f3c-4447-412d-976a-afc8fa0dbbbb"
      },
      "source": [
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X = X[:,:3]\n",
        "y = tf.cast(y, dtype=tf.float32)\n",
        "\n",
        "kbd = KBinsDiscretizer(n_bins=15, encode=\"ordinal\")\n",
        "\n",
        "nunique_vals = pd.DataFrame(X).nunique()\n",
        "X = tf.cast(kbd.fit_transform(X), dtype=tf.int64)\n",
        "\n",
        "gfm = GenFactMachine(\n",
        "    dist=TransNormal,\n",
        "    feature_cards=tf.cast(nunique_vals, tf.int32), \n",
        "    factor_dim=3)\n",
        "\n",
        "\n",
        "\n",
        "hist = gfm.fit(X, y)\n",
        "\n",
        "pd.DataFrame(hist.history).plot(figsize=(15,10))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
            "  'decreasing the number of bins.' % jj)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
            "  'decreasing the number of bins.' % jj)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-cdfeed144f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-bea970ff15ce>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GFMloss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         hist = self.model.fit(\n",
            "\u001b[0;32m<ipython-input-18-bea970ff15ce>\u001b[0m in \u001b[0;36m_build_model\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         params = [\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         ]\n\u001b[1;32m     65\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-bea970ff15ce>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         params = [\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         ]\n\u001b[1;32m     65\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/fm_zoo/fm.py:23 call  *\n        linear_out = self.linear(x)\n    /usr/local/lib/python3.7/dist-packages/fm_zoo/common.py:17 call  *\n        x = x + tf.stop_gradient(self.offsets)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1486 _add_dispatch\n        return gen_math_ops.add_v2(x, y, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:482 add_v2\n        \"AddV2\", x=x, y=y, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'y' of 'AddV2' Op has type int64 that does not match type float32 of argument 'x'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgewD8wXH8Zq"
      },
      "source": [
        "        def obj_func():\n",
        "            params = [\n",
        "               fm(X) for fm in self.fms\n",
        "            ]\n",
        "            ll = tfd.Normal(loc=mu, scale=sigma).log_prob(y)\n",
        "            return -tf.reduce_sum(ll)\n",
        "\n",
        "            return \n",
        "\n",
        "        opt_info = tfp.math.minimize(\n",
        "          lambda: obj_func(), \n",
        "          num_steps=1000, \n",
        "          optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "          return_full_length_trace=False,\n",
        "          convergence_criterion=(\n",
        "            tfp.optimizer.convergence_criteria.LossNotDecreasing(\n",
        "                atol=0.0001, rtol=0.0001)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3wIzQYgpdA5",
        "outputId": "3798e5ac-3b9e-476b-9a41-3e15263829a3"
      },
      "source": [
        "tf.reduce_mean(RestrTransNormal(1.).sample(1000)**2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=7.942813>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abcqo5uzqU85",
        "outputId": "c694682d-287c-4f97-837e-8b8c6f2fec3f"
      },
      "source": [
        "        def obj_func():\n",
        "            params = [\n",
        "               fm(X) for fm in self.fms\n",
        "            ]\n",
        "            ll = tfd.Normal(loc=mu, scale=sigma).log_prob(y)\n",
        "            return -tf.reduce_sum(ll)\n",
        "\n",
        "            return \n",
        "\n",
        "        opt_info = tfp.math.minimize(\n",
        "          lambda: obj_func(), \n",
        "          num_steps=1000, \n",
        "          optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "          return_full_length_trace=False,\n",
        "          convergence_criterion=(\n",
        "            tfp.optimizer.convergence_criteria.LossNotDecreasing(\n",
        "                atol=0.0001, rtol=0.0001)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRfoXeLorNc9",
        "outputId": "3bc5599b-01c3-4545-efcd-72967b09b686"
      },
      "source": [
        "def func(dist, **kwargs):\n",
        "    return partial(dist, **kwargs)\n",
        "\n",
        "func(tfd.Normal, loc=0.0)(scale=2.0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "meWO4iklTIM8",
        "outputId": "c88ac49b-ff55-45da-91c7-040827c095e4"
      },
      "source": [
        "mdl = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(5)),\n",
        "    tf.keras.layers.Dense(10, activation=tf.keras.layers.LeakyReLU()),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(1)                            \n",
        "])\n",
        "\n",
        "mdl.compile(\n",
        "    loss=\"mse\",\n",
        "    optimizer=\"rmsprop\")\n",
        "\n",
        "inp = tf.random.normal(shape=(500,5))\n",
        "target = tf.random.normal(shape=(500,1))\n",
        "\n",
        "hist = mdl.fit(inp, target, batch_size=32, epochs=50)\n",
        "pd.DataFrame(hist.history).plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 1ms/step - loss: 1.6209\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.4831\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1.2880\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1223\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1587\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9622\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9979\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9115\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0340\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9856\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1.0410\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9986\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1.0160\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8795\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8842\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.8993\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9716\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8916\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.8446\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9710\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9978\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0673\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9930\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9609\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9819\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9871\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9123\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9154\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9578\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9360\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9732\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9045\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9608\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9201\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9698\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9489\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9064\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.8241\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9180\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9648\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9297\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9319\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9127\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.9151\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9843\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.8982\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.8658\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8733\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.8852\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb55fc94950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mMEzjDmRyy2",
        "outputId": "712a0a77-c7b5-4c6a-c8f0-e87b1f13c8b1"
      },
      "source": [
        "fm.predict(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48257238],\n",
              "       [0.55737823],\n",
              "       [0.55737823],\n",
              "       [0.5582001 ],\n",
              "       [0.6179424 ],\n",
              "       [0.5582001 ],\n",
              "       [0.49677452],\n",
              "       [0.50840414],\n",
              "       [0.55747545],\n",
              "       [0.55747545],\n",
              "       [0.49024242],\n",
              "       [0.50840414],\n",
              "       [0.49677452],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.54042417],\n",
              "       [0.4901852 ],\n",
              "       [0.54042417],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.4901852 ],\n",
              "       [0.54042417],\n",
              "       [0.54042417],\n",
              "       [0.4901852 ],\n",
              "       [0.54042417],\n",
              "       [0.5948064 ],\n",
              "       [0.5136728 ],\n",
              "       [0.5948064 ],\n",
              "       [0.57338154],\n",
              "       [0.5028088 ],\n",
              "       [0.54654753],\n",
              "       [0.543584  ],\n",
              "       [0.543584  ],\n",
              "       [0.5930207 ],\n",
              "       [0.543584  ],\n",
              "       [0.5930207 ],\n",
              "       [0.5930207 ],\n",
              "       [0.5241455 ],\n",
              "       [0.5241455 ],\n",
              "       [0.5241455 ],\n",
              "       [0.5513705 ],\n",
              "       [0.61428595],\n",
              "       [0.6154118 ],\n",
              "       [0.6154118 ],\n",
              "       [0.57477635],\n",
              "       [0.5794214 ],\n",
              "       [0.5794214 ],\n",
              "       [0.5794214 ],\n",
              "       [0.5698253 ],\n",
              "       [0.51771307],\n",
              "       [0.5224675 ],\n",
              "       [0.5698253 ],\n",
              "       [0.51771307],\n",
              "       [0.5224675 ],\n",
              "       [0.5582001 ],\n",
              "       [0.54654753],\n",
              "       [0.54654753],\n",
              "       [0.5813625 ],\n",
              "       [0.5252637 ],\n",
              "       [0.5252637 ],\n",
              "       [0.46664461],\n",
              "       [0.5271664 ],\n",
              "       [0.46664461],\n",
              "       [0.5271664 ],\n",
              "       [0.5561249 ],\n",
              "       [0.4803071 ],\n",
              "       [0.4803071 ],\n",
              "       [0.4803071 ],\n",
              "       [0.54255027],\n",
              "       [0.5561249 ],\n",
              "       [0.57790333],\n",
              "       [0.57790333],\n",
              "       [0.57790333],\n",
              "       [0.57790333],\n",
              "       [0.5449038 ],\n",
              "       [0.5449038 ],\n",
              "       [0.5449038 ],\n",
              "       [0.5583743 ],\n",
              "       [0.59669626],\n",
              "       [0.59669626],\n",
              "       [0.59669626],\n",
              "       [0.59245884],\n",
              "       [0.57506424],\n",
              "       [0.53007996],\n",
              "       [0.57506424],\n",
              "       [0.46966475],\n",
              "       [0.46966475],\n",
              "       [0.46966475],\n",
              "       [0.5437767 ],\n",
              "       [0.5437767 ],\n",
              "       [0.48334363],\n",
              "       [0.48334363],\n",
              "       [0.4593967 ],\n",
              "       [0.5330631 ],\n",
              "       [0.48334363],\n",
              "       [0.48334363],\n",
              "       [0.5330631 ],\n",
              "       [0.48334363],\n",
              "       [0.48334363],\n",
              "       [0.4593967 ],\n",
              "       [0.47032508],\n",
              "       [0.46664461],\n",
              "       [0.47808862],\n",
              "       [0.4539427 ],\n",
              "       [0.47808862],\n",
              "       [0.5271664 ],\n",
              "       [0.47808862],\n",
              "       [0.5271664 ],\n",
              "       [0.47808862],\n",
              "       [0.47808862],\n",
              "       [0.56265914],\n",
              "       [0.56265914],\n",
              "       [0.48100853],\n",
              "       [0.5335164 ],\n",
              "       [0.48100853],\n",
              "       [0.5335164 ],\n",
              "       [0.5191584 ],\n",
              "       [0.46535423],\n",
              "       [0.46535423],\n",
              "       [0.5011577 ],\n",
              "       [0.5191584 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5011577 ],\n",
              "       [0.5191584 ],\n",
              "       [0.5011577 ],\n",
              "       [0.5011577 ],\n",
              "       [0.46535423],\n",
              "       [0.5191584 ],\n",
              "       [0.46535423],\n",
              "       [0.5191584 ],\n",
              "       [0.46535423],\n",
              "       [0.5483819 ],\n",
              "       [0.5253268 ],\n",
              "       [0.5253268 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5011577 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5253268 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5253268 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5483819 ],\n",
              "       [0.5317514 ],\n",
              "       [0.53020686],\n",
              "       [0.61255187],\n",
              "       [0.61255187],\n",
              "       [0.61255187],\n",
              "       [0.59669626],\n",
              "       [0.61255187],\n",
              "       [0.52795523],\n",
              "       [0.5437767 ],\n",
              "       [0.5437767 ],\n",
              "       [0.45797798],\n",
              "       [0.45797798],\n",
              "       [0.5437767 ],\n",
              "       [0.52795523],\n",
              "       [0.52795523],\n",
              "       [0.6365528 ],\n",
              "       [0.55688655],\n",
              "       [0.6365528 ],\n",
              "       [0.561834  ],\n",
              "       [0.6365528 ],\n",
              "       [0.6365528 ],\n",
              "       [0.5052638 ],\n",
              "       [0.5052638 ],\n",
              "       [0.5794214 ],\n",
              "       [0.6187351 ],\n",
              "       [0.6226147 ],\n",
              "       [0.6187351 ],\n",
              "       [0.5794214 ],\n",
              "       [0.5794214 ],\n",
              "       [0.6187351 ],\n",
              "       [0.5794214 ],\n",
              "       [0.54654753],\n",
              "       [0.5028088 ],\n",
              "       [0.47808862],\n",
              "       [0.4539427 ],\n",
              "       [0.4539427 ],\n",
              "       [0.47808862],\n",
              "       [0.5082673 ],\n",
              "       [0.5271664 ],\n",
              "       [0.5082673 ],\n",
              "       [0.4539427 ],\n",
              "       [0.47808862],\n",
              "       [0.4539427 ],\n",
              "       [0.5271664 ],\n",
              "       [0.53947085],\n",
              "       [0.5561249 ],\n",
              "       [0.4803071 ],\n",
              "       [0.4803071 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.55544627],\n",
              "       [0.55544627],\n",
              "       [0.5241455 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5241455 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.55544627],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5742325 ],\n",
              "       [0.5921104 ],\n",
              "       [0.51771307],\n",
              "       [0.51771307],\n",
              "       [0.51771307],\n",
              "       [0.51771307],\n",
              "       [0.5224675 ],\n",
              "       [0.60676175],\n",
              "       [0.60676175],\n",
              "       [0.5875371 ],\n",
              "       [0.60676175],\n",
              "       [0.60676175],\n",
              "       [0.60676175],\n",
              "       [0.55976737],\n",
              "       [0.52950746],\n",
              "       [0.6266207 ],\n",
              "       [0.5875371 ],\n",
              "       [0.6174678 ],\n",
              "       [0.612784  ],\n",
              "       [0.57477635],\n",
              "       [0.57860065],\n",
              "       [0.57860065],\n",
              "       [0.57860065],\n",
              "       [0.6029491 ],\n",
              "       [0.6029491 ],\n",
              "       [0.6029491 ],\n",
              "       [0.57860065],\n",
              "       [0.57860065],\n",
              "       [0.57860065],\n",
              "       [0.57860065],\n",
              "       [0.57860065],\n",
              "       [0.6029491 ],\n",
              "       [0.565939  ],\n",
              "       [0.5494201 ],\n",
              "       [0.62198126],\n",
              "       [0.5736681 ],\n",
              "       [0.5494201 ],\n",
              "       [0.62668645],\n",
              "       [0.5626327 ],\n",
              "       [0.5626327 ],\n",
              "       [0.62668645],\n",
              "       [0.64074695],\n",
              "       [0.54784733],\n",
              "       [0.5563817 ],\n",
              "       [0.5563817 ],\n",
              "       [0.55747074],\n",
              "       [0.5794214 ],\n",
              "       [0.5028088 ],\n",
              "       [0.5052638 ],\n",
              "       [0.5794214 ],\n",
              "       [0.6071381 ],\n",
              "       [0.6071381 ],\n",
              "       [0.6071381 ],\n",
              "       [0.5617762 ],\n",
              "       [0.57851017],\n",
              "       [0.5617762 ],\n",
              "       [0.5561249 ],\n",
              "       [0.5561249 ],\n",
              "       [0.47979823],\n",
              "       [0.54255027],\n",
              "       [0.47979823],\n",
              "       [0.6389004 ],\n",
              "       [0.6226147 ],\n",
              "       [0.6187351 ],\n",
              "       [0.6071381 ],\n",
              "       [0.54570234],\n",
              "       [0.54570234],\n",
              "       [0.6273022 ],\n",
              "       [0.6273022 ],\n",
              "       [0.64128923],\n",
              "       [0.6273022 ],\n",
              "       [0.51414984],\n",
              "       [0.51414984],\n",
              "       [0.54042417],\n",
              "       [0.4901852 ],\n",
              "       [0.4593967 ],\n",
              "       [0.4593967 ],\n",
              "       [0.51414984],\n",
              "       [0.4593967 ],\n",
              "       [0.4593967 ],\n",
              "       [0.4593967 ],\n",
              "       [0.51414984],\n",
              "       [0.51414984],\n",
              "       [0.55747545],\n",
              "       [0.55747545],\n",
              "       [0.53755873],\n",
              "       [0.49024242],\n",
              "       [0.53755873],\n",
              "       [0.55747545],\n",
              "       [0.49024242],\n",
              "       [0.49024242],\n",
              "       [0.5437767 ],\n",
              "       [0.5437767 ],\n",
              "       [0.5274573 ],\n",
              "       [0.60762817],\n",
              "       [0.6071381 ],\n",
              "       [0.5449038 ],\n",
              "       [0.54252326],\n",
              "       [0.54252326],\n",
              "       [0.54252326],\n",
              "       [0.4971677 ],\n",
              "       [0.54252326],\n",
              "       [0.5449038 ],\n",
              "       [0.5449038 ],\n",
              "       [0.5819184 ],\n",
              "       [0.5582001 ],\n",
              "       [0.5776775 ],\n",
              "       [0.5776775 ],\n",
              "       [0.4971677 ],\n",
              "       [0.5449038 ],\n",
              "       [0.57477635],\n",
              "       [0.5794214 ],\n",
              "       [0.5819184 ],\n",
              "       [0.6273022 ],\n",
              "       [0.64128923],\n",
              "       [0.64128923],\n",
              "       [0.5794214 ],\n",
              "       [0.6187351 ],\n",
              "       [0.55462843],\n",
              "       [0.5687113 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5687113 ],\n",
              "       [0.5320078 ],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5320078 ],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.5687113 ],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.5687113 ],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.49472326],\n",
              "       [0.5687113 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.5320078 ],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5320078 ],\n",
              "       [0.53455615],\n",
              "       [0.5687113 ],\n",
              "       [0.53455615],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.49472326],\n",
              "       [0.5320078 ],\n",
              "       [0.55790734],\n",
              "       [0.5320078 ],\n",
              "       [0.49472326],\n",
              "       [0.5320078 ],\n",
              "       [0.5335164 ],\n",
              "       [0.5335164 ],\n",
              "       [0.5335164 ],\n",
              "       [0.48100853],\n",
              "       [0.48100853],\n",
              "       [0.5330631 ],\n",
              "       [0.4593967 ],\n",
              "       [0.5330631 ],\n",
              "       [0.4593967 ],\n",
              "       [0.4593967 ],\n",
              "       [0.4593967 ],\n",
              "       [0.5330631 ],\n",
              "       [0.4593967 ],\n",
              "       [0.5362311 ],\n",
              "       [0.5347319 ],\n",
              "       [0.5362311 ],\n",
              "       [0.46664461],\n",
              "       [0.5362311 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ae8kcFI2RroW",
        "outputId": "35476a1c-fcc3-44af-d1bc-8f6083312024"
      },
      "source": [
        "pd.DataFrame(hist.history).plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb560bbb750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx4Zl3voQyzC",
        "outputId": "33be600d-31df-40bc-e13f-2f847157d5e0"
      },
      "source": [
        "fm(tf.cast(X, dtype=tf.int64))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(506, 1), dtype=float32, numpy=\n",
              "array([[0.2919633 ],\n",
              "       [0.25897792],\n",
              "       [0.25897792],\n",
              "       [0.22296599],\n",
              "       [0.24901795],\n",
              "       [0.22296599],\n",
              "       [0.24353305],\n",
              "       [0.230096  ],\n",
              "       [0.21192904],\n",
              "       [0.21192904],\n",
              "       [0.296324  ],\n",
              "       [0.230096  ],\n",
              "       [0.24353305],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.29218113],\n",
              "       [0.33529255],\n",
              "       [0.29218113],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.33529255],\n",
              "       [0.29218113],\n",
              "       [0.29218113],\n",
              "       [0.33529255],\n",
              "       [0.29218113],\n",
              "       [0.2762244 ],\n",
              "       [0.26572493],\n",
              "       [0.2762244 ],\n",
              "       [0.23570503],\n",
              "       [0.28262508],\n",
              "       [0.29581124],\n",
              "       [0.26099578],\n",
              "       [0.26099578],\n",
              "       [0.24189958],\n",
              "       [0.26099578],\n",
              "       [0.24189958],\n",
              "       [0.24189958],\n",
              "       [0.32877353],\n",
              "       [0.32877353],\n",
              "       [0.32877353],\n",
              "       [0.27917594],\n",
              "       [0.28229958],\n",
              "       [0.27037475],\n",
              "       [0.27037475],\n",
              "       [0.26550448],\n",
              "       [0.21387994],\n",
              "       [0.21387994],\n",
              "       [0.21387994],\n",
              "       [0.25045064],\n",
              "       [0.28262907],\n",
              "       [0.27428418],\n",
              "       [0.25045064],\n",
              "       [0.28262907],\n",
              "       [0.27428418],\n",
              "       [0.22296599],\n",
              "       [0.29581124],\n",
              "       [0.29581124],\n",
              "       [0.25449857],\n",
              "       [0.25129414],\n",
              "       [0.25129414],\n",
              "       [0.29330543],\n",
              "       [0.2655163 ],\n",
              "       [0.29330543],\n",
              "       [0.2655163 ],\n",
              "       [0.28591412],\n",
              "       [0.2724214 ],\n",
              "       [0.2724214 ],\n",
              "       [0.2724214 ],\n",
              "       [0.2627988 ],\n",
              "       [0.28591412],\n",
              "       [0.29024863],\n",
              "       [0.29024863],\n",
              "       [0.29024863],\n",
              "       [0.29024863],\n",
              "       [0.2592073 ],\n",
              "       [0.2592073 ],\n",
              "       [0.2592073 ],\n",
              "       [0.27771452],\n",
              "       [0.27813506],\n",
              "       [0.27813506],\n",
              "       [0.27813506],\n",
              "       [0.28562167],\n",
              "       [0.29530892],\n",
              "       [0.27586228],\n",
              "       [0.29530892],\n",
              "       [0.29231983],\n",
              "       [0.29231983],\n",
              "       [0.29231983],\n",
              "       [0.31824455],\n",
              "       [0.31824455],\n",
              "       [0.28095517],\n",
              "       [0.28095517],\n",
              "       [0.35077927],\n",
              "       [0.2603516 ],\n",
              "       [0.28095517],\n",
              "       [0.28095517],\n",
              "       [0.2603516 ],\n",
              "       [0.28095517],\n",
              "       [0.28095517],\n",
              "       [0.35077927],\n",
              "       [0.2891972 ],\n",
              "       [0.29330543],\n",
              "       [0.28166085],\n",
              "       [0.35209692],\n",
              "       [0.28166085],\n",
              "       [0.2655163 ],\n",
              "       [0.28166085],\n",
              "       [0.2655163 ],\n",
              "       [0.28166085],\n",
              "       [0.28166085],\n",
              "       [0.30485243],\n",
              "       [0.30485243],\n",
              "       [0.28759116],\n",
              "       [0.26010564],\n",
              "       [0.28759116],\n",
              "       [0.26010564],\n",
              "       [0.280473  ],\n",
              "       [0.34963456],\n",
              "       [0.34963456],\n",
              "       [0.33404505],\n",
              "       [0.280473  ],\n",
              "       [0.29129753],\n",
              "       [0.33404505],\n",
              "       [0.280473  ],\n",
              "       [0.33404505],\n",
              "       [0.33404505],\n",
              "       [0.34963456],\n",
              "       [0.280473  ],\n",
              "       [0.34963456],\n",
              "       [0.280473  ],\n",
              "       [0.34963456],\n",
              "       [0.29129753],\n",
              "       [0.27539942],\n",
              "       [0.27539942],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.33404505],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.27539942],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.27539942],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.29129753],\n",
              "       [0.27397197],\n",
              "       [0.28877643],\n",
              "       [0.29874423],\n",
              "       [0.29874423],\n",
              "       [0.29874423],\n",
              "       [0.27813506],\n",
              "       [0.29874423],\n",
              "       [0.29317525],\n",
              "       [0.31824455],\n",
              "       [0.31824455],\n",
              "       [0.3036687 ],\n",
              "       [0.3036687 ],\n",
              "       [0.31824455],\n",
              "       [0.29317525],\n",
              "       [0.29317525],\n",
              "       [0.36352393],\n",
              "       [0.3362282 ],\n",
              "       [0.36352393],\n",
              "       [0.3446829 ],\n",
              "       [0.36352393],\n",
              "       [0.36352393],\n",
              "       [0.35302195],\n",
              "       [0.35302195],\n",
              "       [0.21387994],\n",
              "       [0.22696018],\n",
              "       [0.21568882],\n",
              "       [0.22696018],\n",
              "       [0.21387994],\n",
              "       [0.21387994],\n",
              "       [0.22696018],\n",
              "       [0.21387994],\n",
              "       [0.29581124],\n",
              "       [0.28262508],\n",
              "       [0.28166085],\n",
              "       [0.35209692],\n",
              "       [0.35209692],\n",
              "       [0.28166085],\n",
              "       [0.28616512],\n",
              "       [0.2655163 ],\n",
              "       [0.28616512],\n",
              "       [0.35209692],\n",
              "       [0.28166085],\n",
              "       [0.35209692],\n",
              "       [0.2655163 ],\n",
              "       [0.27238685],\n",
              "       [0.28591412],\n",
              "       [0.2724214 ],\n",
              "       [0.2724214 ],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.31838486],\n",
              "       [0.31838486],\n",
              "       [0.32877353],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.32877353],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.31838486],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.26805347],\n",
              "       [0.3024633 ],\n",
              "       [0.28262907],\n",
              "       [0.28262907],\n",
              "       [0.28262907],\n",
              "       [0.28262907],\n",
              "       [0.27428418],\n",
              "       [0.24919285],\n",
              "       [0.24919285],\n",
              "       [0.27370983],\n",
              "       [0.24919285],\n",
              "       [0.24919285],\n",
              "       [0.24919285],\n",
              "       [0.2694458 ],\n",
              "       [0.33753034],\n",
              "       [0.29640767],\n",
              "       [0.27370983],\n",
              "       [0.26750505],\n",
              "       [0.2766286 ],\n",
              "       [0.26550448],\n",
              "       [0.34726012],\n",
              "       [0.34726012],\n",
              "       [0.34726012],\n",
              "       [0.2952066 ],\n",
              "       [0.2952066 ],\n",
              "       [0.2952066 ],\n",
              "       [0.34726012],\n",
              "       [0.34726012],\n",
              "       [0.34726012],\n",
              "       [0.34726012],\n",
              "       [0.34726012],\n",
              "       [0.2952066 ],\n",
              "       [0.29091144],\n",
              "       [0.34997696],\n",
              "       [0.25867662],\n",
              "       [0.28243667],\n",
              "       [0.34997696],\n",
              "       [0.3267389 ],\n",
              "       [0.3349756 ],\n",
              "       [0.3349756 ],\n",
              "       [0.3267389 ],\n",
              "       [0.35638955],\n",
              "       [0.29309198],\n",
              "       [0.32609546],\n",
              "       [0.32609546],\n",
              "       [0.31160736],\n",
              "       [0.21387994],\n",
              "       [0.28262508],\n",
              "       [0.35302195],\n",
              "       [0.21387994],\n",
              "       [0.3271775 ],\n",
              "       [0.3271775 ],\n",
              "       [0.3271775 ],\n",
              "       [0.25663942],\n",
              "       [0.2690537 ],\n",
              "       [0.25663942],\n",
              "       [0.28591412],\n",
              "       [0.28591412],\n",
              "       [0.2600281 ],\n",
              "       [0.2627988 ],\n",
              "       [0.2600281 ],\n",
              "       [0.24192475],\n",
              "       [0.21568882],\n",
              "       [0.22696018],\n",
              "       [0.3271775 ],\n",
              "       [0.322828  ],\n",
              "       [0.322828  ],\n",
              "       [0.28545326],\n",
              "       [0.28545326],\n",
              "       [0.3165279 ],\n",
              "       [0.28545326],\n",
              "       [0.28336543],\n",
              "       [0.28336543],\n",
              "       [0.29218113],\n",
              "       [0.33529255],\n",
              "       [0.35077927],\n",
              "       [0.35077927],\n",
              "       [0.28336543],\n",
              "       [0.35077927],\n",
              "       [0.35077927],\n",
              "       [0.35077927],\n",
              "       [0.28336543],\n",
              "       [0.28336543],\n",
              "       [0.21192904],\n",
              "       [0.21192904],\n",
              "       [0.23789029],\n",
              "       [0.296324  ],\n",
              "       [0.23789029],\n",
              "       [0.21192904],\n",
              "       [0.296324  ],\n",
              "       [0.296324  ],\n",
              "       [0.31824455],\n",
              "       [0.31824455],\n",
              "       [0.3039833 ],\n",
              "       [0.31317264],\n",
              "       [0.3271775 ],\n",
              "       [0.2592073 ],\n",
              "       [0.2661269 ],\n",
              "       [0.2661269 ],\n",
              "       [0.2661269 ],\n",
              "       [0.25151393],\n",
              "       [0.2661269 ],\n",
              "       [0.2592073 ],\n",
              "       [0.2592073 ],\n",
              "       [0.28208417],\n",
              "       [0.22296599],\n",
              "       [0.33205166],\n",
              "       [0.33205166],\n",
              "       [0.25151393],\n",
              "       [0.2592073 ],\n",
              "       [0.26550448],\n",
              "       [0.21387994],\n",
              "       [0.28208417],\n",
              "       [0.28545326],\n",
              "       [0.3165279 ],\n",
              "       [0.3165279 ],\n",
              "       [0.21387994],\n",
              "       [0.22696018],\n",
              "       [0.2289482 ],\n",
              "       [0.26483116],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.26483116],\n",
              "       [0.2506103 ],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.2506103 ],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.26483116],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.26483116],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.29353246],\n",
              "       [0.26483116],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.2506103 ],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.2506103 ],\n",
              "       [0.26875907],\n",
              "       [0.26483116],\n",
              "       [0.26875907],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.29353246],\n",
              "       [0.2506103 ],\n",
              "       [0.26749524],\n",
              "       [0.2506103 ],\n",
              "       [0.29353246],\n",
              "       [0.2506103 ],\n",
              "       [0.26010564],\n",
              "       [0.26010564],\n",
              "       [0.26010564],\n",
              "       [0.28759116],\n",
              "       [0.28759116],\n",
              "       [0.2603516 ],\n",
              "       [0.35077927],\n",
              "       [0.2603516 ],\n",
              "       [0.35077927],\n",
              "       [0.35077927],\n",
              "       [0.35077927],\n",
              "       [0.2603516 ],\n",
              "       [0.35077927],\n",
              "       [0.28428626],\n",
              "       [0.29413423],\n",
              "       [0.28428626],\n",
              "       [0.29330543],\n",
              "       [0.28428626]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akJI6As9NCFY"
      },
      "source": [
        "a, b = np.unique(X, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WoaLEnrKaC4",
        "outputId": "93d09c05-99b8-4025-ecd9-fa05f804ed54"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(506, 3), dtype=float32, numpy=\n",
              "array([[0., 0., 1.],\n",
              "       [0., 0., 5.],\n",
              "       [0., 0., 5.],\n",
              "       ...,\n",
              "       [2., 0., 8.],\n",
              "       [4., 0., 8.],\n",
              "       [2., 0., 8.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}