{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_science_and_stochastic_programming.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkXbIBOB3BCei5c/imc9M5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoetGer/decisions-under-uncertainty/blob/main/data_science_and_stochastic_programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCh0ZunZ8y7d",
        "outputId": "b64d0451-7a00-4fad-fa9d-54a514114f17"
      },
      "source": [
        "!pip install cvxpy\r\n",
        "!pip install cvxstoc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (1.0.31)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (1.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy) (0.70.11.1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (0.6.2.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (2.0.7.post1)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy) (2.1.2)\n",
            "Requirement already satisfied: dill>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy) (0.3.3)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy) (0.1.5.post0)\n",
            "Collecting cvxstoc\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/0d/6e47ddb7c55a35c765dc6ddad5b4cc9ade7a0b90fbfa692bf1120819b1d4/cvxstoc-0.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from cvxstoc) (1.4.1)\n",
            "Requirement already satisfied: cvxpy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from cvxstoc) (1.0.31)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from cvxstoc) (1.19.5)\n",
            "Collecting pymc>=2.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/81/9a222c38c65019de9ad5a1ee2448cc4a9b5f7a64eeaf246c77f81c0e6f94/pymc-2.3.8.tar.gz (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->cvxstoc) (2.1.2)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->cvxstoc) (2.0.7.post1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->cvxstoc) (0.6.2.post0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->cvxstoc) (0.70.11.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy>=0.3.5->cvxstoc) (0.1.5.post0)\n",
            "Requirement already satisfied: dill>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy>=0.3.5->cvxstoc) (0.3.3)\n",
            "Building wheels for collected packages: pymc\n",
            "  Building wheel for pymc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymc: filename=pymc-2.3.8-cp37-cp37m-linux_x86_64.whl size=1352865 sha256=faa86fb5422cd7303cbfcc08cc7e03cd833cabe99cff4c89058fedb74f274ed0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/a8/e7/8f3ba91a39294d538a92db052fd1fcba1fca74a58c8b022026\n",
            "Successfully built pymc\n",
            "Installing collected packages: pymc, cvxstoc\n",
            "Successfully installed cvxstoc-0.2.2 pymc-2.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sNQucfT9mRQ"
      },
      "source": [
        "# Data Science and Stochastic Programming\r\n",
        "\r\n",
        "In this notebook we explore, how stochastic programming can be used to incorporate uncertainty stemming from data science models into our decision making process.\r\n",
        "\r\n",
        "Let us start by introducing cvxstoc, a Python package for solving stochastic convex optimization problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS92L-OupWYL"
      },
      "source": [
        "import cvxstoc\r\n",
        "import numpy as np\r\n",
        "import pymc\r\n",
        "\r\n",
        "from cvxstoc import NormalRandomVariable, expectation, prob\r\n",
        "from cvxpy import Maximize, Problem\r\n",
        "from cvxpy.expressions.variable import Variable"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ON_lsQHJpWk",
        "outputId": "4f708823-a6d4-4ce3-ebee-73b5da8a2bf5"
      },
      "source": [
        "# Samples to be taken\r\n",
        "num_samples = 100\r\n",
        "\r\n",
        "# Create problem data.\r\n",
        "n = 5\r\n",
        "mu = np.zeros(n)\r\n",
        "Sigma = 0.1*np.eye(n)\r\n",
        "returns = NormalRandomVariable(mu, Sigma)\r\n",
        "alpha = -0.5\r\n",
        "beta = 0.05\r\n",
        "\r\n",
        "# Create the stochastic optimization problem.\r\n",
        "weights = Variable(n)\r\n",
        "probl = Problem(\r\n",
        "    Maximize(expectation(weights.T*returns, num_samples=num_samples)),\r\n",
        "    [\r\n",
        "      cvxpy.max(weights) <= 0.3,\r\n",
        "      weights >= 0, \r\n",
        "      weights.T*np.ones(n) == 1,\r\n",
        "      prob(weights.T*returns <= alpha, num_samples=num_samples) <= beta\r\n",
        "    ]\r\n",
        ")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pymc/MCMC.py:81: UserWarning: Instantiating a Model object directly is deprecated. We recommend passing variables directly to the Model subclass.\n",
            "  warnings.warn(message)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mvkQKtCfSGW"
      },
      "source": [
        "What we are trying to solve here is a simplified portfolio allocation problem, where the goal is to find a weight vector which maximizes the return under some constraints. \r\n",
        "\r\n",
        "The main differences to a more classical approach is that we are not working with a fixed vector of returns, but we assume that the returns are following a Gaussian distribution (with mean mu and covariance Sigma).\r\n",
        "\r\n",
        "A consequence of this choice is that we are not merely trying to maximize the weighted sum of the returns (= weights.T*returns), but an expectation of this weighted sum with respect to the uncertain returns.\r\n",
        "\r\n",
        "Moreover, while the first three constraints are rather standard (none of the portfolio positions should exceed 30% of the overall portfolio, the weights should be non-negative, and the combined weights add up to one), the last one is different from a deterministic optimization problem. The last constraint restricts the probability of the optimal portfolio to exceed a loss of 50% to 5%, i.e. for 100 samples of the return vector, we would only expect to have 5 times a loss higher than 50% with the optimized weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJFGFj_pfRbZ",
        "outputId": "dcb2f2dc-d0d8-4718-e7e2-ae14f2763c44"
      },
      "source": [
        "probl.solve()\r\n",
        "\r\n",
        "print(probl.status)\r\n",
        "print(\"Optimal value:\", probl.value)\r\n",
        "print(\"Optimal weights:\", weights.value)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "optimal\n",
            "Optimal value: 0.032614506652284166\n",
            "Optimal weights: [3.00000000e-01 9.99999994e-02 3.00000000e-01 6.16178799e-10\n",
            " 3.00000000e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXqkHQjZmKJu"
      },
      "source": [
        "While it is fairly straightforward to see how this approach can be integrated with a data science solution (i.e. the data science model provides mean and covariance estimates for the Gaussian distribution), it is rather limited in its usage with a model.\r\n",
        "\r\n",
        "For example, if we are using a Bayesian model to obtain posterior predictive samples, utilize dropout with a deep learning model to generate samples, or simply not use one of the distributions currently supported by cvxstocm, we would not be able to solve the resulting optimization problem.\r\n",
        "\r\n",
        "In order to simplify the work with more complex distribution, we have developed the following function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56lzSBLdl3LA"
      },
      "source": [
        "import numpy as np\r\n",
        "import pymc\r\n",
        "from cvxstoc import RandomVariable\r\n",
        "\r\n",
        "\r\n",
        "def EmpiricalRandomVariable(name, \r\n",
        "                            samples,\r\n",
        "                            mean,\r\n",
        "                            interpolate=False, \r\n",
        "                            lower=-np.inf, \r\n",
        "                            upper=np.inf):\r\n",
        "    '''\r\n",
        "    Create a pymc node whose distribution comes either from a \r\n",
        "    kernel smoothing density estimate or via boostrapping from \r\n",
        "    the provided samples.\r\n",
        "    '''\r\n",
        "    \r\n",
        "    if interpolate:\r\n",
        "      rv_pymc = pymc.stochastic_from_data(\r\n",
        "          name=rv_name, \r\n",
        "          data=samples, \r\n",
        "          lower=lower, \r\n",
        "          upper=upper)\r\n",
        "    else:\r\n",
        "        nobs = samples.shape[0]\r\n",
        "\r\n",
        "        def logp(value):\r\n",
        "            return -np.log(nobs)\r\n",
        "\r\n",
        "        def random():\r\n",
        "            ridx = np.random.randint(low=0, high=nobs, size=1)\r\n",
        "            return samples[ridx].flatten()\r\n",
        "\r\n",
        "        value = random() \r\n",
        "        dtype = type(value)\r\n",
        "    \r\n",
        "        rv_pymc = pymc.Stochastic(\r\n",
        "            logp = logp,\r\n",
        "            doc = \"A node which bootstrap samples from the provided dataset\",\r\n",
        "            name = name,\r\n",
        "            parents = {},\r\n",
        "            random = random,\r\n",
        "            trace = True,\r\n",
        "            dtype = dtype)\r\n",
        "    \r\n",
        "    metadata = {\"mu\": mean}\r\n",
        "    \r\n",
        "    return RandomVariable(rv=rv_pymc, metadata=metadata)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLT1n2NLqDYq",
        "outputId": "af2eccb7-01fd-4add-c2d0-463e3d0ce2a0"
      },
      "source": [
        "# Samples to be taken\r\n",
        "num_samples = 100\r\n",
        "\r\n",
        "# Create problem data.\r\n",
        "n = 5\r\n",
        "mu = np.zeros(n)\r\n",
        "Sigma = 0.1*np.eye(n)\r\n",
        "returns = EmpiricalRandomVariable(\"EmpiricalRV\", \r\n",
        "                                  NormalRandomVariable(mu, Sigma).sample(100),\r\n",
        "                                  mean = mu,\r\n",
        "                                  interpolate=False)\r\n",
        "alpha = -0.5\r\n",
        "beta = 0.05\r\n",
        "\r\n",
        "# Create the stochastic optimization problem.\r\n",
        "weights = Variable(n)\r\n",
        "probl = Problem(\r\n",
        "    Maximize(expectation(weights.T*returns, num_samples=num_samples)),\r\n",
        "    [\r\n",
        "      cvxpy.max(weights) <= 0.3,\r\n",
        "      weights >= 0, \r\n",
        "      weights.T*np.ones(n) == 1,\r\n",
        "      prob(weights.T*returns <= alpha, num_samples=num_samples) <= beta\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "probl.solve()\r\n",
        "\r\n",
        "print(probl.status)\r\n",
        "print(\"Optimal value:\", probl.value)\r\n",
        "print(\"Optimal weights:\", weights.value)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pymc/MCMC.py:81: UserWarning: Instantiating a Model object directly is deprecated. We recommend passing variables directly to the Model subclass.\n",
            "  warnings.warn(message)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "optimal\n",
            "Optimal value: 0.023429738282685787\n",
            "Optimal weights: [3.00000000e-01 3.00000000e-01 1.00000000e-01 1.19533753e-11\n",
            " 3.00000000e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}